{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3b7f623b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting bs4\n",
      "  Downloading bs4-0.0.1.tar.gz (1.1 kB)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\soyeon jang\\anaconda3\\lib\\site-packages (from bs4) (4.10.0)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\soyeon jang\\anaconda3\\lib\\site-packages (from beautifulsoup4->bs4) (2.2.1)\n",
      "Building wheels for collected packages: bs4\n",
      "  Building wheel for bs4 (setup.py): started\n",
      "  Building wheel for bs4 (setup.py): finished with status 'done'\n",
      "  Created wheel for bs4: filename=bs4-0.0.1-py3-none-any.whl size=1271 sha256=38ff04ce520874c7a1db8d15715d01385b7e8d64234e3d394f7ffc09e28d8a61\n",
      "  Stored in directory: c:\\users\\soyeon jang\\appdata\\local\\pip\\cache\\wheels\\73\\2b\\cb\\099980278a0c9a3e57ff1a89875ec07bfa0b6fcbebb9a8cad3\n",
      "Successfully built bs4\n",
      "Installing collected packages: bs4\n",
      "Successfully installed bs4-0.0.1\n",
      "Collecting selenium\n",
      "  Downloading selenium-4.1.2-py3-none-any.whl (963 kB)\n",
      "Collecting trio~=0.17\n",
      "  Downloading trio-0.20.0-py3-none-any.whl (359 kB)\n",
      "Collecting trio-websocket~=0.9\n",
      "  Downloading trio_websocket-0.9.2-py3-none-any.whl (16 kB)\n",
      "Requirement already satisfied: urllib3[secure,socks]~=1.26 in c:\\users\\soyeon jang\\anaconda3\\lib\\site-packages (from selenium) (1.26.7)\n",
      "Collecting outcome\n",
      "  Downloading outcome-1.1.0-py2.py3-none-any.whl (9.7 kB)\n",
      "Requirement already satisfied: async-generator>=1.9 in c:\\users\\soyeon jang\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.10)\n",
      "Requirement already satisfied: sniffio in c:\\users\\soyeon jang\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.2.0)\n",
      "Requirement already satisfied: sortedcontainers in c:\\users\\soyeon jang\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (2.4.0)\n",
      "Requirement already satisfied: cffi>=1.14 in c:\\users\\soyeon jang\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.14.6)\n",
      "Requirement already satisfied: idna in c:\\users\\soyeon jang\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (3.2)\n",
      "Requirement already satisfied: attrs>=19.2.0 in c:\\users\\soyeon jang\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (21.2.0)\n",
      "Requirement already satisfied: pycparser in c:\\users\\soyeon jang\\anaconda3\\lib\\site-packages (from cffi>=1.14->trio~=0.17->selenium) (2.20)\n",
      "Collecting wsproto>=0.14\n",
      "  Downloading wsproto-1.1.0-py3-none-any.whl (24 kB)\n",
      "Requirement already satisfied: pyOpenSSL>=0.14 in c:\\users\\soyeon jang\\anaconda3\\lib\\site-packages (from urllib3[secure,socks]~=1.26->selenium) (21.0.0)\n",
      "Requirement already satisfied: cryptography>=1.3.4 in c:\\users\\soyeon jang\\anaconda3\\lib\\site-packages (from urllib3[secure,socks]~=1.26->selenium) (3.4.8)\n",
      "Requirement already satisfied: certifi in c:\\users\\soyeon jang\\anaconda3\\lib\\site-packages (from urllib3[secure,socks]~=1.26->selenium) (2021.10.8)\n",
      "Requirement already satisfied: PySocks!=1.5.7,<2.0,>=1.5.6 in c:\\users\\soyeon jang\\anaconda3\\lib\\site-packages (from urllib3[secure,socks]~=1.26->selenium) (1.7.1)\n",
      "Requirement already satisfied: six>=1.5.2 in c:\\users\\soyeon jang\\anaconda3\\lib\\site-packages (from pyOpenSSL>=0.14->urllib3[secure,socks]~=1.26->selenium) (1.16.0)\n",
      "Collecting h11<1,>=0.9.0\n",
      "  Downloading h11-0.13.0-py3-none-any.whl (58 kB)\n",
      "Installing collected packages: outcome, h11, wsproto, trio, trio-websocket, selenium\n",
      "Successfully installed h11-0.13.0 outcome-1.1.0 selenium-4.1.2 trio-0.20.0 trio-websocket-0.9.2 wsproto-1.1.0\n",
      "Requirement already satisfied: pandas in c:\\users\\soyeon jang\\anaconda3\\lib\\site-packages (1.3.4)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in c:\\users\\soyeon jang\\anaconda3\\lib\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: numpy>=1.17.3 in c:\\users\\soyeon jang\\anaconda3\\lib\\site-packages (from pandas) (1.20.3)\n",
      "Requirement already satisfied: pytz>=2017.3 in c:\\users\\soyeon jang\\anaconda3\\lib\\site-packages (from pandas) (2021.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\soyeon jang\\anaconda3\\lib\\site-packages (from python-dateutil>=2.7.3->pandas) (1.16.0)\n",
      "Collecting webdriver-manager\n",
      "  Downloading webdriver_manager-3.5.3-py2.py3-none-any.whl (18 kB)\n",
      "Collecting crayons\n",
      "  Downloading crayons-0.4.0-py2.py3-none-any.whl (4.6 kB)\n",
      "Requirement already satisfied: requests in c:\\users\\soyeon jang\\anaconda3\\lib\\site-packages (from webdriver-manager) (2.26.0)\n",
      "Collecting configparser\n",
      "  Downloading configparser-5.2.0-py3-none-any.whl (19 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\soyeon jang\\anaconda3\\lib\\site-packages (from crayons->webdriver-manager) (0.4.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\soyeon jang\\anaconda3\\lib\\site-packages (from requests->webdriver-manager) (2021.10.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\soyeon jang\\anaconda3\\lib\\site-packages (from requests->webdriver-manager) (2.0.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\soyeon jang\\anaconda3\\lib\\site-packages (from requests->webdriver-manager) (1.26.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\soyeon jang\\anaconda3\\lib\\site-packages (from requests->webdriver-manager) (3.2)\n",
      "Installing collected packages: crayons, configparser, webdriver-manager\n",
      "Successfully installed configparser-5.2.0 crayons-0.4.0 webdriver-manager-3.5.3\n",
      "Collecting service\n",
      "  Downloading service-0.6.0.tar.gz (12 kB)\n",
      "Collecting pid>=2.2.3\n",
      "  Downloading pid-3.0.4-py2.py3-none-any.whl (11 kB)\n",
      "Collecting python-daemon>=2.1.2\n",
      "  Downloading python_daemon-2.3.0-py2.py3-none-any.whl (35 kB)\n",
      "Collecting setproctitle>=1.1.10\n",
      "  Downloading setproctitle-1.2.2-cp39-cp39-win_amd64.whl (10 kB)\n",
      "Requirement already satisfied: psutil>=5.4.8 in c:\\users\\soyeon jang\\anaconda3\\lib\\site-packages (from pid>=2.2.3->service) (5.8.0)\n",
      "Requirement already satisfied: docutils in c:\\users\\soyeon jang\\anaconda3\\lib\\site-packages (from python-daemon>=2.1.2->service) (0.17.1)\n",
      "Collecting lockfile>=0.10\n",
      "  Downloading lockfile-0.12.2-py2.py3-none-any.whl (13 kB)\n",
      "Requirement already satisfied: setuptools in c:\\users\\soyeon jang\\anaconda3\\lib\\site-packages (from python-daemon>=2.1.2->service) (58.0.4)\n",
      "Building wheels for collected packages: service\n",
      "  Building wheel for service (setup.py): started\n",
      "  Building wheel for service (setup.py): finished with status 'done'\n",
      "  Created wheel for service: filename=service-0.6.0-py3-none-any.whl size=7405 sha256=f2575de24a2eb56637f524fbbd1c1e23d10f28c138c545e06e03addb82d3ce81\n",
      "  Stored in directory: c:\\users\\soyeon jang\\appdata\\local\\pip\\cache\\wheels\\51\\93\\bb\\c2361261a209c909774df7d061ec4b577902d10282365e08b4\n",
      "Successfully built service\n",
      "Installing collected packages: lockfile, setproctitle, python-daemon, pid, service\n",
      "Successfully installed lockfile-0.12.2 pid-3.0.4 python-daemon-2.3.0 service-0.6.0 setproctitle-1.2.2\n",
      "Requirement already satisfied: setproctitle in c:\\users\\soyeon jang\\anaconda3\\lib\\site-packages (1.2.2)\n",
      "Requirement already satisfied: webdriver_manager in c:\\users\\soyeon jang\\anaconda3\\lib\\site-packages (3.5.3)\n",
      "Requirement already satisfied: configparser in c:\\users\\soyeon jang\\anaconda3\\lib\\site-packages (from webdriver_manager) (5.2.0)\n",
      "Requirement already satisfied: crayons in c:\\users\\soyeon jang\\anaconda3\\lib\\site-packages (from webdriver_manager) (0.4.0)\n",
      "Requirement already satisfied: requests in c:\\users\\soyeon jang\\anaconda3\\lib\\site-packages (from webdriver_manager) (2.26.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\soyeon jang\\anaconda3\\lib\\site-packages (from crayons->webdriver_manager) (0.4.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\soyeon jang\\anaconda3\\lib\\site-packages (from requests->webdriver_manager) (2021.10.8)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\soyeon jang\\anaconda3\\lib\\site-packages (from requests->webdriver_manager) (3.2)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\soyeon jang\\anaconda3\\lib\\site-packages (from requests->webdriver_manager) (1.26.7)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\soyeon jang\\anaconda3\\lib\\site-packages (from requests->webdriver_manager) (2.0.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install bs4\n",
    "!pip install -U selenium\n",
    "!pip install pandas\n",
    "!pip install webdriver-manager\n",
    "!pip install service\n",
    "!pip install setproctitle\n",
    "!pip3 install webdriver_manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c4309127",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "import pandas as pd\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "import os\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.by import By\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "e2e5a3a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "====== WebDriver manager ======\n",
      "Current google-chrome version is 98.0.4758\n",
      "Get LATEST chromedriver version for 98.0.4758 google-chrome\n",
      "Trying to download new driver from https://chromedriver.storage.googleapis.com/98.0.4758.102/chromedriver_win32.zip\n",
      "Driver has been saved in cache [C:\\Users\\Soyeon Jang\\.wdm\\drivers\\chromedriver\\win32\\98.0.4758.102]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "253\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "25"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# need to change so that it takes user input (keyword extraction from user resume)\n",
    "def search_link(job, city, prov):\n",
    "    url=f'https://www.linkedin.com/jobs/{job}-jobs-{city}-{prov}?trk=homepage-jobseeker_suggested-search&position=1&pageNum=0'\n",
    "    return url\n",
    "\n",
    "wd = webdriver.Chrome(service=Service(ChromeDriverManager().install()))\n",
    "wd.get(search_link('data-scientist', 'waterloo', 'ON'))\n",
    "# instead of doing a link. find element to click and insert search items\n",
    "num_jobs = wd.find_element(by=By.CSS_SELECTOR, value='h1>span').get_attribute('innerText')\n",
    "if num_jobs[-1]=='+':\n",
    "    num_jobs=int(num_jobs.replace(',', '')[:-1])\n",
    "else:\n",
    "    num_jobs=int(num_jobs)\n",
    "print(num_jobs)\n",
    "\n",
    "i = 2\n",
    "list_jobs=[]\n",
    "while i <= (num_jobs/25)+1: \n",
    "    job_lists=wd.find_element(by=By.CLASS_NAME, value='jobs-search__results-list')\n",
    "    jobs=job_lists.find_elements(by=By.TAG_NAME, value='li') # returns a list\n",
    "    wd.execute_script(\"window.scrollTo(0, document.documentElement.scrollHeight);\")\n",
    "    i = i + 1\n",
    "    try:\n",
    "        xpath='/html/body/main/div/section/button'\n",
    "        wd.find_element(by=By.XPATH, value=xpath).click()\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "len(jobs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "49e6c679",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_id= []\n",
    "job_title = []\n",
    "company_name = []\n",
    "location = []\n",
    "date = []\n",
    "job_link = []\n",
    "\n",
    "for job in jobs:\n",
    "    job_title0 = job.find_element(by=By.CSS_SELECTOR, value='h3').get_attribute('innerText')\n",
    "    job_title.append(job_title0)\n",
    "    \n",
    "    company_name0 = job.find_element(by=By.CSS_SELECTOR, value='h4').get_attribute('innerText')\n",
    "    company_name.append(company_name0)\n",
    "\n",
    "    location0 = job.find_element(by=By.CSS_SELECTOR, value='[class=\\'job-search-card__location\\']').get_attribute('innerText')\n",
    "    location.append(location0)\n",
    "\n",
    "    date0=job.find_element(by=By.CSS_SELECTOR, value='div>div>time').get_attribute('datetime')\n",
    "    date.append(date0)\n",
    "    \n",
    "    job_link0=job.find_element(by=By.CSS_SELECTOR, value='a').get_attribute('href')\n",
    "    job_link.append(job_link0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "bdf8aa7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "jd = []\n",
    "seniority = []\n",
    "emp_type = []\n",
    "job_func = []\n",
    "industries = []\n",
    "\n",
    "for item in range(len(jobs)):\n",
    "    job_func0=[]\n",
    "    industries0=[]\n",
    "    # clicking job to view job details\n",
    "    job_click_path = f'/html/body/div[1]/div/main/section[2]/ul/li[{item+1}]/div/a'\n",
    "    job_click=job.find_element(by=By.XPATH, value=job_click_path).click()\n",
    "\n",
    "    jd_path = '/html/body/div[1]/div/section/div[2]/div[1]/section[1]/div/div/section'\n",
    "    jd0=job.find_element(by=By.XPATH, value=jd_path).get_attribute('innerText')\n",
    "    jd.append(jd0)\n",
    "    \n",
    "    time.sleep(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "16c226c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_data = pd.DataFrame({\n",
    "    'Date': date,\n",
    "    'Company': company_name,\n",
    "    'Title': job_title,\n",
    "    'Location': location,\n",
    "    'Description': jd,\n",
    "    'Link': job_link\n",
    "})# cleaning description column\n",
    "\n",
    "job_data['Description'] = job_data['Description'].str.replace('\\n',' ')\n",
    "# job_data.to_excel('LinkedIn Job.xlsx', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "a90b8cd4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Company</th>\n",
       "      <th>Title</th>\n",
       "      <th>Location</th>\n",
       "      <th>Description</th>\n",
       "      <th>Link</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-02-25</td>\n",
       "      <td>Limbik</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Waterloo, Ontario, Canada</td>\n",
       "      <td>Limbik is the leading information defense syst...</td>\n",
       "      <td>https://ca.linkedin.com/jobs/view/data-scienti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-02-27</td>\n",
       "      <td>Praemo</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Kitchener, Ontario, Canada</td>\n",
       "      <td>Limbik is the leading informat...</td>\n",
       "      <td>https://ca.linkedin.com/jobs/view/data-scienti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-03-01</td>\n",
       "      <td>TripleLift</td>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>Kitchener, Ontario, Canada</td>\n",
       "      <td>Responsibilities Build machine...</td>\n",
       "      <td>https://ca.linkedin.com/jobs/view/senior-data-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-01-18</td>\n",
       "      <td>Siemens</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Kitchener, Ontario, Canada</td>\n",
       "      <td>About TripleLiftTripleLift is ...</td>\n",
       "      <td>https://ca.linkedin.com/jobs/view/data-scienti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-02-26</td>\n",
       "      <td>PerkinElmer, Inc.</td>\n",
       "      <td>Machine Learning Engineer</td>\n",
       "      <td>Kitchener, Ontario, Canada</td>\n",
       "      <td>Change the future with us.We a...</td>\n",
       "      <td>https://ca.linkedin.com/jobs/view/machine-lear...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date            Company                      Title  \\\n",
       "0  2022-02-25             Limbik             Data Scientist   \n",
       "1  2022-02-27             Praemo             Data Scientist   \n",
       "2  2022-03-01         TripleLift      Senior Data Scientist   \n",
       "3  2022-01-18            Siemens             Data Scientist   \n",
       "4  2022-02-26  PerkinElmer, Inc.  Machine Learning Engineer   \n",
       "\n",
       "                     Location  \\\n",
       "0   Waterloo, Ontario, Canada   \n",
       "1  Kitchener, Ontario, Canada   \n",
       "2  Kitchener, Ontario, Canada   \n",
       "3  Kitchener, Ontario, Canada   \n",
       "4  Kitchener, Ontario, Canada   \n",
       "\n",
       "                                         Description  \\\n",
       "0  Limbik is the leading information defense syst...   \n",
       "1                  Limbik is the leading informat...   \n",
       "2                  Responsibilities Build machine...   \n",
       "3                  About TripleLiftTripleLift is ...   \n",
       "4                  Change the future with us.We a...   \n",
       "\n",
       "                                                Link  \n",
       "0  https://ca.linkedin.com/jobs/view/data-scienti...  \n",
       "1  https://ca.linkedin.com/jobs/view/data-scienti...  \n",
       "2  https://ca.linkedin.com/jobs/view/senior-data-...  \n",
       "3  https://ca.linkedin.com/jobs/view/data-scienti...  \n",
       "4  https://ca.linkedin.com/jobs/view/machine-lear...  "
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1817665a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
